---
title: "13. Multivariate methods"
author: "jsg"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y %H:%M')`"
output:
  html_document:
    toc: true
    toc_float: true
    keep_md: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

Function to help check packages. will see if package in installed, install if not,
and load. input must be in quotes. only works for one at a time.

```{r}

local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})

checkPackage <- function(x){
  if (x %in% row.names(installed.packages()) == F)install.packages(x)
  library(x, character.only = T)
}
```

## Multivariate  model fitting

### MANOVA 

* https://rstudio-pubs-static.s3.amazonaws.com/142692_508137b868e84f239064e90ff1960da6.html
* http://mason.gmu.edu/~alaemmer/bio314/manova
* https://homepages.inf.ed.ac.uk/bwebb/statistics/MANOVA2.pdf

Let's use the iris dataset to explain MANOVA.Load the dataset.

```{r}
head(iris)
dim(iris)
str(iris)
```

Plot the different outcomes they measured

```{r}
library(ggplot2)
library(reshape)
irisshow <- melt(iris,id=c("Species"))
ggplot(irisshow,aes(x=variable,y=value,fill=Species))+
  geom_boxplot()
```

Since we measured multiple responses, we could do ANOVA's but multiple tests and 
correlated.  Note variance-covariance matrix

```{r}
var(iris[,1:4])
cor(iris[,1:4])
```


Multiple options exist for tests. 

```{r}
m <- manova(cbind(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)~Species,
            data=iris)
summary(m)
```

Follow up can mean doing several one way ANOVAs

```{r}
summary.aov(m) 
```

### PERMANOVA

* https://f-santos.gitlab.io/2020-05-07-npmanova.html
* https://archetypalecology.wordpress.com/2018/02/21/permutational-multivariate-analysis-of-variance-permanova-in-r-preliminary/

if normality assumpions are not met, you can use a permuation-based PERMANOVA. Note
it requires to make diffferent objects for response and explanatory variables, as
vegan package often separates these.

```{r}
checkPackage("vegan")
outcomes <- iris[, c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")]
p <- adonis2(outcomes~iris$Species)
p
```

You can carry out pairwise comparison using

```{r}
checkPackage('devtools')
install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
checkPackage("pairwiseAdonis")
pairwise.adonis(outcomes, iris$Species, sim.method = "euclidean",
                p.adjust.m = "bonferroni")
```

### ANOSIM

* https://danstich.github.io/stich/classes/BIOL217/11_multivariate.html 

```{r}
a <- anosim(vegdist(outcomes), grouping = iris$Species)
summary(a)
```

## Ordination

### Polar/Bray-Curtis

```{r}
data(dune)
#use "extreme" vegan for this historic approach
checkPackage("devtools")
install_github("jarioksa/natto")
checkPackage("natto")

dis <- dist(dune, method = "binary") ## Jaccard index
ord <- polarord(dis, k = 1)
ord
plot(ord)
summary(eigenvals(ord))
```


### PCA

* https://ourcodingclub.github.io/tutorials/ordination/#section1

```{r}
PCA <- rda(dune, scale = FALSE)
summary(PCA)
# Use scale = TRUE if your variables are on different scales (e.g. for abiotic variables).
# Here, all species are measured on the same scale 
# So use scale = FALSE

# Now plot a bar plot of relative eigenvalues. This is the percentage variance explained by each axis
barplot(as.vector(PCA$CA$eig)/sum(PCA$CA$eig)) 
screeplot(PCA)# not corrected
# How much of the variance in our dataset is explained by the first principal component?

# Calculate the percent of variance explained by first two axes
sum((as.vector(PCA$CA$eig)/sum(PCA$CA$eig))[1:2]) # 79%, this is ok.
# Also try to do it for the first three axes

# Now, we`ll plot our results with the plot function
plot(PCA)
plot(PCA, display = "sites", type = "points")
plot(PCA, display = "species", type = "text")
```

Evaluate outcomes and biplot

```{r}
#using rda
summary(PCA)
biplot(PCA, choices = c(1,2), type = c("text", "points"), xlim = c(-5,10), scale=0,
       main= "Correlation biplot (scale = 0)") # biplot of axis 1 vs 2
biplot(PCA, choices = c(1,2), type = c("text", "points"), 
       main = "Distance biplot (scale = 1)", xlim = c(-5,10), scale = 1) # biplot of axis 1 vs 2
biplot(PCA, choices = c(1,3), type = c("text","points")) # biplot of axis 1 vs 3


# You can extract the species and site scores on the new PC for further analyses:
sitePCA <- PCA$CA$u # Site scores
speciesPCA <- PCA$CA$v # Species scores

# In a biplot of a PCA, species' scores are drawn as arrows 
# that point in the direction of increasing values for that variable
# use prcomp to generate both types
# http://strata.uga.edu/8370/lecturenotes/principalComponents.html
# https://www.r-bloggers.com/2021/11/biplots-are-everywhere-where-do-they-come-from/
PCApc <- prcomp(dune, scale = FALSE)
biplot(PCApc, choices = c(1,2), xlim = c(-5,10), pc.biplot = T,
       main= "Correlation biplot") # biplot of axis 1 vs 2
biplot(PCApc, choices = c(1,2), xlim = c(-5,10),
       main= "Distance biplot") # biplot of axis 1 vs 2
biplot(PCApc, choices = c(1,2), 
       main = "Distance biplot", xlim = c(-5,10),  pc.biplot = T) # biplot of axis 1 vs 2
biplot(PCA, choices = c(1,3), type = c("text","points")) # biplot of axis 1 vs 3

data(dune.env)
dune.env.new <- dune.env
dune.env.new$pc1 <- data.frame(sitePCA)$PC1
dune.env.new$pc2 <- data.frame(sitePCA)$PC2
library(ggplot2)
ggplot(dune.env.new, aes(x=pc1, y=pc2, shape=Use, color=Use))+
  geom_point(size=2)
impact <- lm(pc1 ~ Use, dune.env.new)
par(mfrow=c(2,2))
plot(impact)
par(mfrow=c(1,1))
library(car)
Anova(impact, type= "III")
library(Rmisc)
impact_summary <- summarySE(dune.env.new, measurevar = "pc1", groupvars = "Use")
ggplot(impact_summary, aes(x=Use, y=pc1, shape=Use, color=Use))+
  geom_point(size=5, stat = "identity", color = "black") +
  geom_errorbar(aes(ymin=pc1-ci, ymax=pc1+ci, colour=Use), size = 1,
                width = 0)
```
### CCA

```{r}
cca_dune <- cca(dune)
summary(cca_dune)
plot(cca_dune, type= "t")
```


### RDA

* https://dmcglinn.github.io/quant_methods/lessons/multivariate_models.html


```{r}
rda_dune <- rda(dune~., data=dune.env)
rda_dune
RsquareAdj(rda_dune)
plot(rda_dune, type='n', scaling=1)
orditorp(rda_dune, display='sp', cex=0.5, scaling=1, col='blue')
text(rda_dune, display='cn', col='red')
```

### CCA

* https://dmcglinn.github.io/quant_methods/lessons/multivariate_models.html


```{r}
cca_dune = cca(dune ~ ., data=dune.env)
cca_dune
RsquareAdj(cca_dune, 100)
```

### Hypothesis testing

* https://dmcglinn.github.io/quant_methods/lessons/multivariate_models.html

You can test related hypotheses using permutations

```{r}
anova(rda_dune, permutations=999)
anova(rda_dune, by='margin', permutations=999)
anova(cca_dune, permutations = 999)
anova(cca_dune, by='margin', permutations = 999)
```

or consider nested models.

```{r}
rda_dune_use_removed <- update(rda_dune, . ~ . - Use)
anova(rda_dune, rda_dune_use_removed)
```

### NMDS

* https://peat-clark.github.io/BIO381/veganTutorial.html
* https://danstich.github.io/stich/classes/BIOL217/11_multivariate.html

```{r}
nmds_dune <- metaMDS(dune, k =2)
nmds_dune
stressplot(nmds_dune)
plot(nmds_dune)
ordiplot(nmds_dune,type="n") #Ordination plot function especially for congested plots
orditorp(nmds_dune,display="species",col="red",air=0.01) #The function adds text or points to ordination plots
orditorp(nmds_dune,display="sites",cex=1.25,air=0.01)
```

if we had a treatment applied to varous plots, we can consider impact on grouping
graphically.

* https://jonlefcheck.net/2012/10/24/nmds-tutorial-in-r/

```{r}
ordiplot(nmds_dune,type="n")
ordihull(nmds_dune,groups=dune.env$Use,draw="polygon",col="grey90",label=T)
orditorp(nmds_dune,display="species",col="red",air=0.01)
orditorp(nmds_dune,display="sites",cex=1.25,air=0.01)
```

## Classification

### discriminant analysis

* https://www.r-bloggers.com/2018/03/discriminant-analysis-statistics-all-the-way/

```{r}
library(MASS)
lda_iris <- lda(Species ~ ., iris)
summary(lda_iris)
Predictions <- predict(lda_iris,iris)
table(Predictions$class, iris$Species)
ldahist(data = Predictions$x[,1], g=iris$Species)
ldahist(data = Predictions$x[,2], g=iris$Species)
```

### clustering

Finding optimal number of groups

* https://rpubs.com/AnanyaDu/361293

#### elbow method

* https://rpubs.com/AnanyaDu/361293

```{r}
#set possible number
k.max = 19
wss<- sapply(1:k.max,function(k){kmeans(iris[,1:4],k,nstart = 20,iter.max = 20)$tot.withinss})
plot(1:k.max,wss, type= "b", xlab = "Number of clusters(k)", ylab = "Within cluster sum of squares")
```

or

* https://uc-r.github.io/kmeans_clustering
* https://rpubs.com/AnanyaDu/361293

```{r}
library(cluster)    # clustering algorithms
library(factoextra)
fviz_nbclust(dune, kmeans, method = "wss")
```

#### silhouette method

```{r}
fviz_nbclust(dune, kmeans, method = "silhouette")
```

#### gap stat

```{r}
gap_stat <- clusGap(dune, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
```

#### fit final model

```{r}
final <- kmeans(dune, 4, nstart = 25)
print(final)
fviz_cluster(final, data = dune)
```

## Tree models 

This needs to be moved to rmd format

```{r}
#trees are useful way of handling data visually and allow first look
#building the classification tree
#install if necessary
#example with famous iris dataset (built-in)
#good for species classification!
library(rpart)
iris_tree_initial <- rpart(Species ~ ., data = iris, method = "class", 
                           minsplit = 2, minbucket = 1)
plot(iris_tree_initial)
text(iris_tree_initial)
#or for a prettier graph
require(rattle)
fancyRpartPlot(iris_tree_initial, main="Iris")

#what if you want fewer splits (less complex model)
#can use defaults for buckets 
iris_tree_initial_auto <- rpart(Species ~ ., data = iris)
fancyRpartPlot(iris_tree_initial_auto, main="Iris")

#or minimize complexity parameter (good for larger models)
iris_tree_model_2<- prune(iris_tree_initial, 
                          cp =   iris_tree_initial$cptable[which.min(iris_tree_initial$cptable[,"xerror"]),"CP"])
#is using this to make decisions
iris_tree_initial$cptable
fancyRpartPlot(iris_tree_model_2)

#validation techniques
#UNDER CONSTRUCTION
#need 0/1 column for for prediction
iris$virginica <- iris$Species
levels(iris$virginica)[levels(iris$virginica) == "virginica"]  <- "1"
levels(iris$virginica)[levels(iris$virginica) %in% c("setosa", "versicolor")] <- "0"
iris$virginica <- as.numeric(as.character(iris$virginica))

#compare glm and gam 
require(mgcv)
require(MASS)
library(MuMIn)

iris_glm <- glm(virginica ~ . - Species, iris, family = binomial)
summary(iris_glm)
iris_glm_final <- stepAIC(iris_glm)

iris_gam <- gam(virginica ~ s(Sepal.Length) + s(Sepal.Width) + 
                  s(Petal.Length) + s(Petal.Width), data = iris)
summary(iris_gam)
iris_gam_a <-update(iris_gam, . ~ . - s(Petal.Width))
summary(iris_gam_a)
iris_gam_b <-update(iris_gam_a, . ~ . - s(Sepal.Width))
summary(iris_gam_b)

AICc(iris_gam_b,  iris_glm_final)

#compare visually using AUC
#calculate AUROC (AUC)
require(ROCR)
iris_glm_final_predict<-prediction(fitted.values(iris_glm_final), iris$virginica)
iris_glm_final_performance<-performance(iris_glm_final_predict,"tpr","fpr")
#to see auc
plot(iris_glm_final_performance, main = "glm AUC")

#compare to gam
iris_gam_b_predict<-prediction(fitted.values(iris_gam_b), iris$virginica)
iris_gam_b_performance<-performance(iris_gam_b_predict,"tpr","fpr")
#to see auc
plot(iris_gam_b_performance, main = "gam AUC")

#cross validation
require(boot)
#K is the number of groups to put data into. default is "leave-one"out" design
iris_glm_final_cv<-cv.glm(iris,  iris_glm_final)
str(iris_glm_final_cv)
#delta is the prediction error and the adjusted rate - use adjusted to minimize
#impact of sampling or outliers
```

## SEM

Needs to be updated.

```{r}
library(lavaan)
#data from Keeley et al. 2005 and extensions in Grace and Keeley 2006 exploring how 
#fire severity interacts with stand age and cover
keeley <- read.csv("http://byrneslab.net/classes/lavaan_materials/Keeley_rawdata_select4.csv ")

#sem vs lm####
keeley_formula1 <- 'firesev ~ age'
class(keeley_formula1)
keeley_sem1 <- sem(keeley_formula1, data = keeley)
summary(keeley_sem1)

keeley_lm <- lm(firesev ~ age, data = keeley)
summary(keeley_lm)
summary(keeley_sem1, standardize = T, rsq = T)

#plot
library(lavaanPlot)
lavaanPlot(model = keeley_sem1, coefs = TRUE)
lavaanPlot(model = keeley_sem1, coefs = TRUE,
           stand=TRUE)

#2nd model####
keeley_formula2 <- '
firesev ~ age
cover ~ firesev
'

keeley_sem2 <- sem(keeley_formula2, data = keeley)
summary(keeley_sem2, standardize = T, rsq = T)
lavaanPlot(model = keeley_sem2, coefs = TRUE)
lavaanPlot(model = keeley_sem2, coefs = TRUE,
           stand=TRUE)

#3rd model####
keeley_formula3 <- '
firesev ~ age
cover ~ firesev + age
'

keeley_sem3 <- sem(keeley_formula3, data = keeley)
summary(keeley_sem3, standardize = T)
lavaanPlot(model = keeley_sem3, coefs = TRUE)
lavaanPlot(model = keeley_sem3, coefs = TRUE,
           stand=TRUE)
#another layout
lavaanPlot(model = keeley_sem3, coefs = TRUE, stand=TRUE,
           graph_options = list(layout = "circo"),sig = 0.05)

#compare####
anova(keeley_sem2, keeley_sem3) #null is that models are different!
```

